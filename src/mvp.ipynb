{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification: cats & dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle imports up-front\n",
    "import glob\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation\n",
    "\n",
    "### 1.1. Load the data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the training data\n",
    "training_data_path='../train/data/train'\n",
    "\n",
    "# Get a list of training dog and cat images\n",
    "training_dogs=glob.glob(f'{training_data_path}/dog/dog.*')\n",
    "training_cats=glob.glob(f'{training_data_path}/cat/cat.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,2,figsize=(6, 4))\n",
    "\n",
    "for cat, dog, row in zip(training_cats, training_dogs, axs):\n",
    "    for animal, ax in zip([cat, dog], row):\n",
    "        animal=image.load_img(animal)\n",
    "        animal=image.img_to_array(animal)\n",
    "        animal/=255.0\n",
    "        ax.imshow(animal)\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA\n",
    "\n",
    "Let's take a look at a few of our images to get a feel for how image data is structured.\n",
    "\n",
    "### 2.1. Image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "def preprocess_image(filepath, target_size=(224, 224)):\n",
    "    # Load the image with the target size\n",
    "    img = load_img(filepath, target_size=target_size)\n",
    "    # Convert the image to an array\n",
    "    img_array = img_to_array(img)\n",
    "    # Normalize the pixel values\n",
    "    img_array = img_array / 255.0\n",
    "    return img_array\n",
    "\n",
    "# Example: Preprocess one cat and one dog image\n",
    "cat_image = preprocess_image(training_cats[0])\n",
    "dog_image = preprocess_image(training_dogs[0])\n",
    "\n",
    "print(f'Cat image shape: {cat_image.shape}')\n",
    "print(f'Dog image shape: {dog_image.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define required variables\n",
    "training_data_path = '../train/data/train'  # Update this path as per your dataset\n",
    "img_height = 128  # Height to resize the images\n",
    "img_width = 128   # Width to resize the images\n",
    "batch_size = 32   # Batch size for training\n",
    "\n",
    "# Set up data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,  # Normalize pixel values\n",
    "    rotation_range=40,  # Random rotation\n",
    "    width_shift_range=0.2,  # Random width shift\n",
    "    height_shift_range=0.2,  # Random height shift\n",
    "    shear_range=0.2,  # Shear transformations\n",
    "    zoom_range=0.2,  # Random zoom\n",
    "    horizontal_flip=True,  # Random horizontal flip\n",
    "    fill_mode='nearest'  # Fill mode for newly created pixels\n",
    ")\n",
    "\n",
    "# Create the training generator\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    training_data_path,\n",
    "    target_size=(img_height, img_width),  # Resize all images to (img_height, img_width)\n",
    "    batch_size=batch_size,  # Number of images per batch\n",
    "    class_mode='binary'  # Binary classification (e.g., cats vs dogs)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch, sample_labels = next(train_generator)\n",
    "fig, axs = plt.subplots(3, 3, figsize=(8, 8))\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(sample_batch[i])\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess one image (e.g., a cat image)\n",
    "sample_image = preprocess_image(training_cats[0])\n",
    "\n",
    "# Separate the RGB channels\n",
    "red_channel = sample_image[:, :, 0]\n",
    "green_channel = sample_image[:, :, 1]\n",
    "blue_channel = sample_image[:, :, 2]\n",
    "\n",
    "# Plot histograms for each channel\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(red_channel.ravel(), bins=256, color='red', alpha=0.7)\n",
    "plt.title('Red Channel Histogram')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(green_channel.ravel(), bins=256, color='green', alpha=0.7)\n",
    "plt.title('Green Channel Histogram')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(blue_channel.ravel(), bins=256, color='blue', alpha=0.7)\n",
    "plt.title('Blue Channel Histogram')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Image dimensions\n",
    "\n",
    "Let's take a look at a random sample of images from the dataset and see what their dimensions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import load_img\n",
    "\n",
    "# Initialize lists to store widths and heights\n",
    "widths = []\n",
    "heights = []\n",
    "\n",
    "# Loop over a subset of images (e.g., 200 images)\n",
    "sample_images = training_cats[:100] + training_dogs[:100]  # Adjust number as needed\n",
    "\n",
    "for image_path in sample_images:\n",
    "    img = load_img(image_path)  # Load image\n",
    "    widths.append(img.width)   # Extract width\n",
    "    heights.append(img.height) # Extract height\n",
    "\n",
    "# Plot histograms of widths and heights\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(widths, bins=30, color='blue', alpha=0.7)\n",
    "plt.title('Histogram of Image Widths')\n",
    "plt.xlabel('Width (pixels)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(heights, bins=30, color='green', alpha=0.7)\n",
    "plt.title('Histogram of Image Heights')\n",
    "plt.xlabel('Height (pixels)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Image aspect ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import load_img\n",
    "\n",
    "# Initialize lists to store widths and heights\n",
    "widths = []\n",
    "heights = []\n",
    "\n",
    "# Loop over a subset of images (e.g., 200 images)\n",
    "sample_images = training_cats[:100] + training_dogs[:100]  # Adjust number as needed\n",
    "\n",
    "for image_path in sample_images:\n",
    "    img = load_img(image_path)  # Load image\n",
    "    widths.append(img.width)   # Extract width\n",
    "    heights.append(img.height) # Extract height\n",
    "\n",
    "# Plot histograms of widths and heights\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(widths, bins=30, color='blue', alpha=0.7)\n",
    "plt.title('Histogram of Image Widths')\n",
    "plt.xlabel('Width (pixels)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(heights, bins=30, color='green', alpha=0.7)\n",
    "plt.title('Histogram of Image Heights')\n",
    "plt.xlabel('Height (pixels)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build the model\n",
    "\n",
    "### 3.1. Prepare images for streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets(training_data_path: str, image_dim: int, batch_size: int=16):\n",
    "\n",
    "    training_dataset=tf.keras.utils.image_dataset_from_directory(\n",
    "        training_data_path,\n",
    "        validation_split=0.2,\n",
    "        subset='training',\n",
    "        seed=315,\n",
    "        image_size=(image_dim, image_dim),\n",
    "        batch_size=batch_size\n",
    "    ).repeat()\n",
    "\n",
    "    validation_dataset=tf.keras.utils.image_dataset_from_directory(\n",
    "        training_data_path,\n",
    "        validation_split=0.2,\n",
    "        subset='validation',\n",
    "        seed=315,\n",
    "        image_size=(image_dim, image_dim),\n",
    "        batch_size=batch_size\n",
    "    ).repeat()\n",
    "\n",
    "    return training_dataset, validation_dataset\n",
    "\n",
    "training_dataset, validation_dataset=make_datasets(training_data_path, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(image_dim, learning_rate):\n",
    "\n",
    "    initializer=tf.keras.initializers.GlorotUniform(seed=315)\n",
    "\n",
    "    model=Sequential([\n",
    "        layers.Input((image_dim, image_dim, 3)),\n",
    "        layers.Rescaling(1./255),\n",
    "        layers.Conv2D(16, 3, padding='same', activation='relu', kernel_initializer=initializer),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(32, 3, padding='same', activation='relu', kernel_initializer=initializer),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, padding='same', activation='relu', kernel_initializer=initializer),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu', kernel_initializer=initializer),\n",
    "        layers.Dense(1, activation='sigmoid', kernel_initializer=initializer)\n",
    "    ])\n",
    "\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['binary_accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model=compile_model(128, 0.001)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results=model.fit(\n",
    "  training_dataset,\n",
    "  validation_data=validation_dataset,\n",
    "  epochs=10,\n",
    "  steps_per_epoch=5,\n",
    "  validation_steps=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = compile_model(128, 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, layers, optimizers\n",
    "import tensorflow as tf\n",
    "\n",
    "def compile_model(image_dim, learning_rate):\n",
    "    initializer = tf.keras.initializers.GlorotUniform(seed=315)\n",
    "\n",
    "    model = Sequential([\n",
    "        layers.Input((image_dim, image_dim, 3)),  # Input layer for images of size (image_dim, image_dim, 3)\n",
    "        layers.Rescaling(1.0 / 255),  # Rescale pixel values to [0, 1]\n",
    "        layers.Conv2D(16, 3, padding='same', activation='relu', kernel_initializer=initializer),  # First Conv layer\n",
    "        layers.MaxPooling2D(),  # First MaxPool layer\n",
    "        layers.Conv2D(32, 3, padding='same', activation='relu', kernel_initializer=initializer),  # Second Conv layer\n",
    "        layers.MaxPooling2D(),  # Second MaxPool layer\n",
    "        layers.Conv2D(64, 3, padding='same', activation='relu', kernel_initializer=initializer),  # Third Conv layer\n",
    "        layers.MaxPooling2D(),  # Third MaxPool layer\n",
    "        layers.Flatten(),  # Flatten feature maps\n",
    "        layers.Dense(128, activation='relu', kernel_initializer=initializer),  # Fully connected layer\n",
    "        layers.Dense(1, activation='sigmoid', kernel_initializer=initializer)  # Output layer for binary classification\n",
    "    ])\n",
    "\n",
    "    optimizer = optimizers.Adam(learning_rate=learning_rate)  # Optimizer with the given learning rate\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['binary_accuracy'])  # Compile the model\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "training_results = model.fit(\n",
    "    training_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=5,\n",
    "    validation_steps=5\n",
    ")\n",
    "\n",
    "# Access training_results\n",
    "print(training_results.history)  # View available keys in training history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metrics from training_results\n",
    "history = training_results.history\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Training and Validation Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['binary_accuracy'], label='Training Accuracy')\n",
    "plt.plot(history['val_binary_accuracy'], label='Validation Accuracy', linestyle='--')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Training and Validation Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss', linestyle='--')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Binary Cross-Entropy Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import Sequential, layers, optimizers\n",
    "\n",
    "# Define a function to create the model\n",
    "def compile_model(image_dim, learning_rate):\n",
    "    initializer = tf.keras.initializers.GlorotUniform(seed=315)\n",
    "    model = Sequential([\n",
    "        layers.Input((image_dim, image_dim, 3)),\n",
    "        layers.Rescaling(1.0 / 255),\n",
    "        layers.Conv2D(16, 3, padding='same', activation='relu', kernel_initializer=initializer),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(32, 3, padding='same', activation='relu', kernel_initializer=initializer),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, padding='same', activation='relu', kernel_initializer=initializer),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu', kernel_initializer=initializer),\n",
    "        layers.Dense(1, activation='sigmoid', kernel_initializer=initializer)\n",
    "    ])\n",
    "\n",
    "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['binary_accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define hyperparameters to test\n",
    "learning_rates = [0.0005, 0.001, 0.005]\n",
    "batch_sizes = [16, 32, 64]\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = []\n",
    "\n",
    "# Loop through learning rates and batch sizes\n",
    "for lr in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        print(f\"Testing learning rate: {lr}, batch size: {batch_size}\")\n",
    "        \n",
    "        # Prepare datasets\n",
    "        train_dataset, val_dataset = make_datasets(training_data_path, image_dim=128, batch_size=batch_size)\n",
    "        \n",
    "        # Compile the model\n",
    "        model = compile_model(image_dim=128, learning_rate=lr)\n",
    "        \n",
    "        # Train the model for a few epochs\n",
    "        training_results = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data=val_dataset,\n",
    "            epochs=5,  # Train for fewer epochs for quicker experimentation\n",
    "            steps_per_epoch=5,\n",
    "            validation_steps=5,\n",
    "            verbose=0  # Suppress verbose output for clarity\n",
    "        )\n",
    "        \n",
    "        # Record results\n",
    "        final_train_accuracy = training_results.history['binary_accuracy'][-1]\n",
    "        final_val_accuracy = training_results.history['val_binary_accuracy'][-1]\n",
    "        results.append({\n",
    "            'learning_rate': lr,\n",
    "            'batch_size': batch_size,\n",
    "            'train_accuracy': final_train_accuracy,\n",
    "            'val_accuracy': final_val_accuracy\n",
    "        })\n",
    "\n",
    "# Convert results to a DataFrame for better visualization\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Optimization Results\", dataframe=results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters (replace with the actual best values from your optimization results)\n",
    "best_learning_rate = 0.001  # Replace with the best learning rate\n",
    "best_batch_size = 32        # Replace with the best batch size\n",
    "\n",
    "# Prepare datasets with the best batch size\n",
    "train_dataset, val_dataset = make_datasets(training_data_path, image_dim=128, batch_size=best_batch_size)\n",
    "\n",
    "# Compile the model with the best learning rate\n",
    "model = compile_model(image_dim=128, learning_rate=best_learning_rate)\n",
    "\n",
    "# Train the model for longer\n",
    "training_results = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=20,  # Train for more epochs\n",
    "    steps_per_epoch=50,  # Increase steps per epoch to cover more data\n",
    "    validation_steps=20,  # Increase validation steps\n",
    "    verbose=1  # Show detailed training progress\n",
    ")\n",
    "\n",
    "# Plot training and validation metrics\n",
    "history = training_results.history\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['binary_accuracy'], label='Training Accuracy')\n",
    "plt.plot(history['val_binary_accuracy'], label='Validation Accuracy', linestyle='--')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss', linestyle='--')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Binary Cross-Entropy Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Paths\n",
    "test_data_path = '/workspaces/dltdestryk-gperdrizet-image-classification-project/test1'\n",
    "organized_test_path = '/workspaces/dltdestryk-gperdrizet-image-classification-project/organized_test'\n",
    "\n",
    "# Create subdirectories for each class\n",
    "os.makedirs(os.path.join(organized_test_path, 'cat'), exist_ok=True)\n",
    "os.makedirs(os.path.join(organized_test_path, 'dog'), exist_ok=True)\n",
    "\n",
    "# Move files into their respective class folders\n",
    "for file_name in os.listdir(test_data_path):\n",
    "    if file_name.startswith('cat'):\n",
    "        shutil.move(os.path.join(test_data_path, file_name), os.path.join(organized_test_path, 'cat', file_name))\n",
    "    elif file_name.startswith('dog'):\n",
    "        shutil.move(os.path.join(test_data_path, file_name), os.path.join(organized_test_path, 'dog', file_name))\n",
    "\n",
    "print(\"Test data reorganized successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "# Load and preprocess test images\n",
    "test_images = []\n",
    "test_labels = []  # Optional: Only if you have labels\n",
    "for file_name in os.listdir(test_data_path):\n",
    "    img = load_img(os.path.join(test_data_path, file_name), target_size=(128, 128))\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    test_images.append(img_array)\n",
    "\n",
    "# Convert to numpy array\n",
    "test_images = np.array(test_images)\n",
    "\n",
    "# Predict on test images\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "# Print predictions (for binary classification)\n",
    "print(predictions[:10])  # Example predictions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
